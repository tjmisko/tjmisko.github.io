---
layout: post
title: "Intelligence as a Sort of Compression"
subtitle: "Searle, Bostrom, and the Chinese Room" 
author: "Tristan Misko"
---

It was a chilly Sunday afternoon as I walked down Bancroft Way towards Downtown Berkeley BART to pick up my partner from the station.  I decided to dip into a podcast entitled "A Conversation with Nick Bostrom" recorded in 2017 for the now-defunct show *Voices in AI* with X.  

With all the AI buzz in the last six months

What does Bostrom's argument remind me of? All of the finicky arguments about reasoning about infinity and the ways in which we must be careful in our thought experiments.  

Combinatorial arguments


The infinitude of textural detail in the world.  Painting and drawing are hard because we have to learn to see through our concepts and abstractions and see the world as it is.  Such an interesting way of coming into knowledge or understanding something.  Attention and sensitivity.

Looking around at the world and realizing how many concepts I'm projecting onto it at once.  Beautiful kind of mindfulness.  The notion of the ground.  The lightposts.  Attention.  Subconscious recognitions.  Relevance filtering, done automatically. 

Neural networks as intuition machines. It doesn't know how or why it got to where it is.  We do this all the time.  

20 February 2023
Voices in AI, “A Conversation with Nick Bostrom”
The host raised Searle’s Chinese Room argument that AI cannot be conscious, which I had never heard before
Basically, the thrust of the argument lies in imagining a guy who does not speak chinese but gets these written notes slipped under the door and pattern matches with the books in the room to return brilliant answers
Eventually he memorizes all the books and walks around on the street giving out these great answers, but can he be said to be intelligent or conscious?
Bostrom has a great set of resposnses
First, intelligence is not equivalent to consciousness.  We can imagine intelligent entities which are not conscious quite easily.  Cf. the argument Jen and I hatched that consciousness is roughly equal to intelligence plus self-awareness.
Second, since brains are physical objects, roughly three pounds, and are quite intelligent, we must conclude that consciousness emerges from physical processes, and we might further venture that consciousness is in fact a computational process
Third, the Chinese room argument sounds good until you consider how large the “lookup table” would have to be to enable the guy to respond; it would not be physically possible for it to exist unless there was some kind of compression algorithm
The notion of compression is where the “intelligence” in the system lies
Efficient compression/compactification is a very CS way of phrasing the quasioptimal argument, another way into what we’re talking about
Bostrom also had a nice thought about the long run future: education can be the place where we equip and orient people to live in a world where what they make and do is not the most important part of their lives
This has happened before: the aristocratic leisure classes lived what we would consider good lives on balance
It’s a culture thing, and to the extent that smart people have any outsized influence on the culture, it’s through the education system
How can I think about the cultural impact of what I’m doing? How can I shape the culture to be ready for the future I’m imagining? What leverage do I have?  Where can I exercise it?