---
layout: post
title: "[Leading a ragtag group into battle]"
subtitle: ""
author: "Tristan Misko"
---

I've been working on the SSPI for almost three years now, and I'm so excited to be in a position to implement the overhaul our data collection process that I've been dreaming of ever since I took charge of the database.  

# Current System

The data management system on which the SSPI team has relied for the last five years has been straining as the size, scope, and detail of our project has grown.  

We use Google Sheets as our primary database because it is easy to use, accessible to all team members, and handles collaboration seamlessly.  This environment met our needs when our project was smaller, but as the number and complexity of our indicators has grown, the cracks have started to show.  

All of the insight and value that the SSPI provides depends on the accuracy and reliability of our indicator data.  As we move toward publication, we must guarantee that our data is correct and up-to-date for our results to have any claim to validity.  Much of our data was hand-collected by team members years ago, making a replication a time-consuming and tedious process of tracking down the original source (dead links and data reporting website redesigns are the mortal enemy of good documentation) and checking data values by hand.  More often than not, 



we've been stuck in a low-code paradigm in which bugs and sorting errors are difficult to trace and fix because there is no record of the operations performed when producing an indicator.





We've been trying to freeze our database

I've been in charge of the data collection process for the SSPI team for the last two years or so, and I've been formulating big plans.  
